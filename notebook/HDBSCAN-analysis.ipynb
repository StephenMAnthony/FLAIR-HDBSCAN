{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b9e1ee-a3c3-46e0-ab72-9c4bbadc3b6f",
   "metadata": {
    "id": "f631ae2d-c169-461c-937a-3446a78abe79",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1ygAs8EMNlIim2ypwmvQn9yN1LbY3hWHV\" alt=\"Drawing\"  width=\"30%\"/><center>\n",
    "\n",
    "# <center><strong>Development notebook</strong></center>\n",
    "<br/>\n",
    "\n",
    "<br/><center>This notebook allows you to visualize the data used in the **FLAIR #2 challenge**.<br/>The code bellow works with the toy dataset (subset) provided in the starting-kit alongside this notebook as well as with the full FLAIR-two dataset accessible after registration to the competition.</center> <br/> \n",
    "<center>**We also strongly advise you to read the data technical description provided in the datapaper.**</center>\n",
    "<br/> <br/> \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a551697-f7df-4079-9719-d658971e8a34",
   "metadata": {},
   "source": [
    "Handle all the generic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012f4c2-c578-4206-93ff-fe2f8ed0dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38dda1-76dd-4409-a682-a4866f1419ed",
   "metadata": {},
   "source": [
    "Import code from or based upon the FLAIR-2 reference implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc9829-c35d-42b0-b6f2-8c92b51748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAIR_path = join(Path.cwd().parents[0],'FLAIR-code/src')\n",
    "if FLAIR_path not in sys.path:\n",
    "    sys.path.append(FLAIR_path)\n",
    "\n",
    "from data_display import (display_nomenclature,\n",
    "                            display_samples, \n",
    "                            display_time_serie,\n",
    "                            display_all_with_semantic_class, \n",
    "                            display_all, \n",
    "                            read_dates, \n",
    "                            filter_dates)\n",
    "from load_data import load_data\n",
    "from FusedDataset import FusedDataset\n",
    "from calc_miou import calc_miou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ebbdb-2eda-4d14-85ff-8d5a30542764",
   "metadata": {
    "id": "e147039d-d45e-4ab4-a670-7093c603d7ed",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Load Data</font>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Use reference code to create lists containing the paths to the input images (`images`) and supervision masks (`masks`) files of the dataset.<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214019e8-6f88-438b-ab7f-5a62c3cc8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/app/FLAIR-HDBSCAN/flair-2-config.yml\" \n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Creation of the train, val, and test dictionaries with the data file paths\n",
    "# Note that due to using the toy dataset we assign 100% of the data for training. \n",
    "# While not best practice for machine learning, for the toy dataset when using the stock code and less than 100%, issues randomly arise when using the reference loader\n",
    "# as the random selection can result in some semantic classes not being represented. If the full FLAIR #2 dataset were employed, validation data should be separate. \n",
    "# Due to size limitations on HDBSCAN, for actual training we downsample to ~1 % of the training data for training and use 100% of the training data for fitting. \n",
    "d_train, d_val, d_test = load_data(config, val_percent=1)\n",
    "\n",
    "# Convert to torch Datasets\n",
    "train_dataset = FusedDataset(dict_files=d_train, config=config)\n",
    "valid_dataset = FusedDataset(dict_files=d_val, config=config)\n",
    "test_dataset = FusedDataset(dict_files=d_val, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ca57a-be05-40c0-9360-86e06d64fa98",
   "metadata": {
    "id": "a0bc22ea-1ef0-4f21-aa8c-171807d11362",
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "<hr style=\"height:3px;border-width:0;color:red;background-color:red\">   \n",
    "\n",
    "# <center><font color='red'>PART-2: Development area</font></center>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Area under active development. \n",
    "\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea08e0-9e4a-441f-af25-4d944924336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = join(Path.cwd().parents[0],'code')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6d3b1-bcec-44ec-b033-e1de8612a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import display\n",
    "reload(display)\n",
    "from display import box_whisker_by_class\n",
    "from display import display_confusion\n",
    "\n",
    "import classifier\n",
    "reload(classifier)\n",
    "from classifier import extract_aerial_spectra\n",
    "from classifier import train_and_validate_model\n",
    "from classifier import normalize_aerial_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f9320-16d3-4823-8fc6-6eb072471399",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_model_and_predictions = train_and_validate_model(train_dataset, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d782943-1153-4482-b415-653485d77e2f",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "Display the confusion matrix and MIOU metric for k-nearest neighbor classification on the aerial spectra. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16dfd9b-2f22-4405-8c84-72d6563e39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion(knn_model_and_predictions['true_classes'], knn_model_and_predictions['predicted_classes'], config, 'knn validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3971856-220c-4bd9-8cf5-25f280b460f5",
   "metadata": {
    "id": "a0bc22ea-1ef0-4f21-aa8c-171807d11362",
    "tags": []
   },
   "source": [
    "#### <br><br>\n",
    "<hr style=\"height:3px;border-width:0;color:red;background-color:red\">   \n",
    "\n",
    "# <center><font color='red'>PART-4: Spectral Normalization</font></center>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Spectral analysis may be improved by separating the spectral profile from the intensity. Normalize all the spectra and add an additional feature corresponding to the intensity. One reason this can be useful is that due to a combination of sun angle and/or off-nadir imaging, there might be shadows. Shadows will generally have a similar spectral shape but different intensity. \n",
    "\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb2ae4-aac3-48ad-8c43-038e7f3accb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_spectra, labels = extract_spectra(train_dataset, config)\n",
    "normalized_spectra = normalize_spectra(original_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630f8ff-52fd-446c-9e0b-f772d30f0eca",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "The plot below shows a scatter plot of the distribution of values of the first two raw spectral components. A strong correlation is observed between the values of these components, related to differences in intensity. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc635c97-a94e-4de2-9fb5-0a462d3ef152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwds = {'alpha': 0.1, 's': 80, 'linewidths':0}\n",
    "plt.scatter(original_spectra[0,:], original_spectra[1,:], color='b', **plot_kwds)\n",
    "plt.xlabel(\"Spectral Component #1\")\n",
    "plt.ylabel(\"Spectral Component #2\")\n",
    "plt.title(\"Raw Spectra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff582a-05fb-44cf-93d2-f31a98949458",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "The plot below shows a scatter plot of the distribution of values of the first two spectral components after normalization. Normalization significantly reduces the correlation between these components. Separate clusters and lobes become much more apparent. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879f581-b16b-40a4-aa1c-96c9bf38f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwds = {'alpha': 0.1, 's': 80, 'linewidths':0}\n",
    "plt.scatter(normalized_spectra[0,:], normalized_spectra[1,:], color='b', **plot_kwds)\n",
    "plt.xlabel(\"Spectral Component #1\")\n",
    "plt.ylabel(\"Spectral Component #2\")\n",
    "plt.title(\"Normalized Spectra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0373cd2-1a63-419c-8a03-af67a196fb7e",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "The plot below shows a scatter plot of the distribution of values of the first two spectral components. A strong correlation is observed between the values of these components, related to differences in intensity. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5145e7c-fdf3-4ef2-bcd2-93859b5fd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_normalized_model_and_predictions = train_and_validate_knn(train_dataset, config, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3389f1-0fbc-4c47-b575-8eb4a2e7b069",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "Display the confusion matrix and MIOU metric for k-nearest neighbor classification on the normalized aerial spectra with appended intensity. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fbdd6c-2b7e-4ba2-a078-6920ebf0aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion(knn_normalized_model_and_predictions['true_classes'], knn_normalized_model_and_predictions['predicted_classes'], config, 'knn normalized spectra validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb13b341-ff99-4894-b2a8-28607e85500e",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "These results indicate that normalizing the spectra and appending the intensity do not improve the classification. One possibility is that appending the intensity is the issue. Try without that. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1dd5f-1285-4679-8888-fa2cc73094d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_normalized_no_intensity_model_and_predictions = train_and_validate_knn(train_dataset, config, normalize=True, append_intensity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b5f9-758a-4803-86ca-f707acd153b5",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "Display the confusion matrix and MIOU metric for k-nearest neighbor classification on the normalized aerial spectra with appended intensity. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5ad97-7a9a-48b7-a946-bd23eabcd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion(knn_normalized_no_intensity_model_and_predictions['true_classes'], knn_normalized_no_intensity_model_and_predictions['predicted_classes'], config, 'knn normalized spectra no intensity validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aaaa18-a56c-4ce2-8eda-ceb90ac1eab7",
   "metadata": {
    "id": "da00bce4-c1da-4843-9705-e573a74a7dd9",
    "tags": []
   },
   "source": [
    "<br/><hr> \n",
    "\n",
    "Neither of these showed improvement over the baseline k-nearest neighbor classifier. <br/> <hr><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e43cd-12e4-403f-a67a-9fd7a98d2685",
   "metadata": {
    "id": "a0bc22ea-1ef0-4f21-aa8c-171807d11362",
    "tags": []
   },
   "source": [
    "###### <br><br>\n",
    "<hr style=\"height:3px;border-width:0;color:red;background-color:red\">   \n",
    "\n",
    "# <center><font color='red'>PART-5: HDBSCAN analysis of aerial imagery</font></center>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Here, I apply HDBSCAN clustering to the aerial imagery training data from the FLAIR #2 toy dataset.<br/> \n",
    "\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213e4e0-15e5-49df-8ed3-d7a5fcb1ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64592aef-6c54-4e8a-b3b0-902f9e3815c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(classifier)\n",
    "from classifier import normalize_spectra\n",
    "from classifier import extract_spectra\n",
    "from classifier import assign_class_to_cluster\n",
    "from classifier import train_and_validate_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19678739-c8ac-4f15-8e00-6625be04b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdbscan_model_and_predictions = train_and_validate_hdbscan(train_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356dd70d-6ae7-4dd2-a754-36273417ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion(hdbscan_model_and_predictions['true_classes'], hdbscan_model_and_predictions['predicted_classes'], config, 'HDBSCAN Validation cluster size 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbbb02c-ad85-42ec-b332-6a7ada249d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933a1a4-1076-4a31-971e-f961a5e9a368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24b98a-15c6-4b46-92da-d89ed51943da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7017109-8388-4f1a-94b7-1a634543e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f072f-2098-43cf-94a9-d28767e9272b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe15a6a-13bd-4b46-8c8b-04d6fb258009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b7271-372f-46fb-a902-226469e8f945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412d0d8-0979-47fd-a1e4-00c83d9639fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93535c67-9931-4f8b-8e07-d96b164aa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "def sentinel_pixels(aerial_images, sentinel_images, sentinel_masks, centroids, sentinel_products, idx):\n",
    "\n",
    "    # Read in the aerial image. \n",
    "    with rasterio.open(aerial_images[idx], 'r') as f:\n",
    "        im = f.read().swapaxes(0, 2).swapaxes(0, 1)\n",
    "\n",
    "    # Determine the dates for all corresponding sentinel images\n",
    "    sentinel_dates = read_dates(sentinel_products[idx])\n",
    "    \n",
    "    #Read in the corresponding sentinel images\n",
    "    sen = np.load(sentinel_images[idx])[:,[2,1,0],:,:]/2000\n",
    "    \n",
    "    # Read in the corresponding cloud masks\n",
    "    clouds = np.load(sentinel_masks[idx])\n",
    "\n",
    "    dates_to_keep = filter_dates(sen, clouds)\n",
    "    print(len(dates_to_keep))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    sen_spatch = sen[:, centroids[idx][0]-int(20):centroids[idx][0]+int(20),centroids[idx][1]-int(20):centroids[idx][1]+int(20)]\n",
    "    print(centroids[idx])\n",
    "\n",
    "    return im\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fe087-4103-4011-9889-61be77f23e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0,38):\n",
    "    im = sentinel_pixels(train_aerial_images, train_sentinel_images, train_sentinel_masks, train_centroids, train_sentinel_products, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d78bc-4c6a-4c63-9f29-315f4a04df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = sentinel_pixels(train_aerial_images, train_sentinel_images, train_sentinel_masks, train_centroids, train_sentinel_products, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a7d1a-3332-4dad-a604-1f8e3b9f3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "67-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54ec4f-9e05-4cb3-8821-a64a52f9f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[:, :, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075d917-eb62-443d-9c1c-1c187419db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a4104-32d9-4352-a7cb-9155b7af979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6a632-3e25-4370-9e5a-6b7ae2d0d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef17505-300d-469d-91a3-f9a4faeca0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(np.squeeze(sen[idx,:,:,:]), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadec0d-fa58-47b8-a52f-a48274d233e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(clouds[idx,1,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271628c2-3887-4c01-bd0f-60d09d3f2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the spectra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ee5e8-5a48-4576-b1ed-b2c20e3bd73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014f2eb-2f84-4888-8688-52d40d8be76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hex2color\n",
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4b8f3-58a8-46be-b9a6-5de8ccbe5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_colors = {\n",
    "1   : '#db0e9a',\n",
    "2   : '#938e7b',\n",
    "3   : '#f80c00',\n",
    "4   : '#a97101',\n",
    "5   : '#1553ae',\n",
    "6   : '#194a26',\n",
    "7   : '#46e483',\n",
    "8   : '#f3a60d',\n",
    "9   : '#660082',\n",
    "10  : '#55ff00',\n",
    "11  : '#fff30d',\n",
    "12  : '#e4df7c',\n",
    "13  : '#3de6eb',\n",
    "14  : '#ffffff',\n",
    "15  : '#8ab3a0',\n",
    "16  : '#6b714f',\n",
    "17  : '#c5dc42',\n",
    "18  : '#9999ff',\n",
    "19  : '#000000'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c94690-fde6-4a68-b0c7-9c0bde3ceb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_color(arr_2d: np.ndarray, palette: dict = lut_colors) -> np.ndarray:\n",
    "    rgb_palette = {k: tuple(int(i * 255) for i in hex2color(v)) for k, v in palette.items()}\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "    for c, i in rgb_palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "    return arr_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751563f-ae11-4c3f-a755-d5d5b30f7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(images, masks, sentinel_imgs, centroid, palette=lut_colors, idx=0) -> None:\n",
    "    print(idx)\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize = (10, 6)); fig.subplots_adjust(wspace=0.0, hspace=0.15)\n",
    "    fig.patch.set_facecolor('black')\n",
    "\n",
    "    with rasterio.open(images[idx], 'r') as f:\n",
    "        im = f.read([1,2,3]).swapaxes(0, 2).swapaxes(0, 1)\n",
    "    with rasterio.open(masks[idx], 'r') as f:\n",
    "        mk = f.read([1])\n",
    "        mk = convert_to_color(mk[0], palette=palette)\n",
    "    \n",
    "    sen = np.load(sentinel_imgs[idx])[20,[2,1,0],:,:]/2000\n",
    "    offset = (0, 0)\n",
    "    sen_spatch = sen[:, centroid[idx][0]-int(20) + offset[0]:centroid[idx][0]+int(20) + offset[0],\n",
    "        centroid[idx][1]-int(20) + offset[1]:centroid[idx][1]+int(20) + offset[1]]\n",
    "    transform = T.CenterCrop(10)\n",
    "    sen_aerialpatch = transform(torch.as_tensor(np.expand_dims(sen_spatch, axis=0))).numpy()\n",
    "    sen = np.transpose(sen, (1,2,0))\n",
    "    sen_spatch = np.transpose(sen_spatch, (1,2,0))\n",
    "    sen_aerialpatch = np.transpose(sen_aerialpatch[0], (1,2,0))\n",
    "\n",
    "    #axs = axs if isinstance(axs[], np.ndarray) else [axs]\n",
    "    ax0 = axs[0][0] ; ax0.imshow(im);ax0.axis('off')\n",
    "    ax1 = axs[0][1] ; ax1.imshow(mk, interpolation='nearest') ;ax1.axis('off')\n",
    "    ax2 = axs[0][2] ; ax2.imshow(im); ax2.imshow(mk, interpolation='nearest', alpha=0.25); ax2.axis('off')\n",
    "    ax3 = axs[1][0] ; ax3.imshow(sen);ax3.axis('off')\n",
    "    ax4 = axs[1][1] ; ax4.imshow(sen_spatch);ax4.axis('off')\n",
    "    ax5 = axs[1][2] ; ax5.imshow(sen_aerialpatch);ax5.axis('off')\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    rect = Rectangle((centroid[idx][1]-5.12, centroid[idx][0]-5.12), 10.24, 10.24, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax3.add_patch(rect)\n",
    "    rect = Rectangle((14.88, 14.88), 10.24, 10.24, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax4.add_patch(rect)\n",
    "    \n",
    "    ax0.set_title('RGB Image', size=12,fontweight=\"bold\",c='w')\n",
    "    ax1.set_title('Ground Truth Mask', size=12,fontweight=\"bold\",c='w')\n",
    "    ax2.set_title('Overlay Image & Mask', size=12,fontweight=\"bold\",c='w')\n",
    "    ax3.set_title('Sentinel super area', size=12,fontweight=\"bold\",c='w')\n",
    "    ax4.set_title('Sentinel super patch', size=12,fontweight=\"bold\",c='w')\n",
    "    ax5.set_title('Sentinel over the aerial patch', size=12,fontweight=\"bold\",c='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e5c25-efa8-43d9-96bb-bf7b22510ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(train_aerial_images, train_labels, train_sentinel_images, train_centroids, idx=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e28eb-3451-427a-b047-5f44ea328957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image 2\n",
    "# Image 5\n",
    "# Image 9 - clear half pixel shift\n",
    "# Image 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016fb7b-7937-4be5-b042-aff0c65b8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-100, 100)\n",
    "\n",
    "#-int(20):int(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22fac1-ad3b-47ba-889c-25ff5861ccd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
