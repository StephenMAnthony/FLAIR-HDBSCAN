{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b9e1ee-a3c3-46e0-ab72-9c4bbadc3b6f",
   "metadata": {
    "id": "f631ae2d-c169-461c-937a-3446a78abe79",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1ygAs8EMNlIim2ypwmvQn9yN1LbY3hWHV\" alt=\"Drawing\"  width=\"30%\"/><center>\n",
    "\n",
    "# <center><strong>Development notebook</strong></center>\n",
    "<br/>\n",
    "\n",
    "<br/><center>This notebook allows you to visualize the data used in the **FLAIR #2 challenge**.<br/>The code bellow works with the toy dataset (subset) provided in the starting-kit alongside this notebook as well as with the full FLAIR-two dataset accessible after registration to the competition.</center> <br/> \n",
    "<center>**We also strongly advise you to read the data technical description provided in the datapaper.**</center>\n",
    "<br/> <br/> \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a551697-f7df-4079-9719-d658971e8a34",
   "metadata": {},
   "source": [
    "Handle all the generic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012f4c2-c578-4206-93ff-fe2f8ed0dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38dda1-76dd-4409-a682-a4866f1419ed",
   "metadata": {},
   "source": [
    "Import code from or based upon the FLAIR-2 reference implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc9829-c35d-42b0-b6f2-8c92b51748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAIR_path = join(Path.cwd().parents[0],'FLAIR-code/src')\n",
    "if FLAIR_path not in sys.path:\n",
    "    sys.path.append(FLAIR_path)\n",
    "\n",
    "from data_display import (display_nomenclature,\n",
    "                            display_samples, \n",
    "                            display_time_serie,\n",
    "                            display_all_with_semantic_class, \n",
    "                            display_all, \n",
    "                            read_dates, \n",
    "                            filter_dates)\n",
    "from load_data import load_data\n",
    "from FusedDataset import FusedDataset\n",
    "from calc_miou import calc_miou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ebbdb-2eda-4d14-85ff-8d5a30542764",
   "metadata": {
    "id": "e147039d-d45e-4ab4-a670-7093c603d7ed",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Load Data</font>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Use reference code to create lists containing the paths to the input images (`images`) and supervision masks (`masks`) files of the dataset.<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214019e8-6f88-438b-ab7f-5a62c3cc8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/app/FLAIR-HDBSCAN/flair-2-config.yml\" \n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Creation of the train, val, and test dictionaries with the data file paths\n",
    "# Note that due to using the toy dataset we assign 100% of the data for training. \n",
    "# While not best practice for machine learning, for the toy dataset when using the stock code and less than 100%, issues randomly arise when using the reference loader\n",
    "# as the random selection can result in some semantic classes not being represented. If the full FLAIR #2 dataset were employed, validation data should be separate. \n",
    "# Due to size limitations on HDBSCAN, for actual training we downsample to ~1 % of the training data for training and use 100% of the training data for fitting. \n",
    "d_train, d_val, d_test = load_data(config, val_percent=1)\n",
    "\n",
    "# Convert to torch Datasets\n",
    "train_dataset = FusedDataset(dict_files=d_train, config=config)\n",
    "valid_dataset = FusedDataset(dict_files=d_val, config=config)\n",
    "test_dataset = FusedDataset(dict_files=d_val, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ca57a-be05-40c0-9360-86e06d64fa98",
   "metadata": {
    "id": "a0bc22ea-1ef0-4f21-aa8c-171807d11362",
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "<hr style=\"height:3px;border-width:0;color:red;background-color:red\">   \n",
    "\n",
    "# <center><font color='red'>PART-2: Development area</font></center>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Area under active development. \n",
    "\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea08e0-9e4a-441f-af25-4d944924336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = join(Path.cwd().parents[0],'code')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6d3b1-bcec-44ec-b033-e1de8612a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import display\n",
    "reload(display)\n",
    "from display import display_confusion\n",
    "\n",
    "import classifier\n",
    "reload(classifier)\n",
    "from classifier import train_and_validate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db30181-6314-4f78-a233-0e47626471d3",
   "metadata": {
    "id": "a0bc22ea-1ef0-4f21-aa8c-171807d11362",
    "tags": []
   },
   "source": [
    "### <br><br>\n",
    "<hr style=\"height:3px;border-width:0;color:red;background-color:red\">   \n",
    "\n",
    "# <center><font color='red'>PART-12: Data Fusion - Spectral Normalization</font></center>\n",
    "\n",
    "<br/><hr>\n",
    "This section shows the effects of data fusion of satellite imagery with aerial imagery combined with spectral normalization\n",
    "<br/> \n",
    "\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f88f0-44dd-41b7-9cfc-8f9e1ae45ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_fusion_normalized = train_and_validate_model(train_dataset, config, use_satellite=True, use_hdbscan=False, robust_scale=False, scale_by_intensity=True, append_intensity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0d0b1-cc93-4e24-97b5-cc291a0f3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion(knn_fusion_normalized['true_classes'], knn_fusion_normalized['predicted_classes'], config, 'KNN Fusion w/ Spectral Normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e55744-4a50-4859-b4ba-dcc2448ae56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f knn_fusion_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8fc96-1519-4557-bdd0-5feab4096481",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdbscan_fusion_normalized = train_and_validate_model(train_dataset, config, use_satellite=True, use_hdbscan=True, robust_scale=False, scale_by_intensity=True, append_intensity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40179b-51bd-439a-996d-faa16be5680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion(hdbscan_fusion_normalized['true_classes'], hdbscan_fusion_normalized['predicted_classes'], config, 'HDBSCAN Fusion w/ Spectral Normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628b94a-d911-4b0c-a00e-eb15d7511c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f hdbscan_fusion_normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
